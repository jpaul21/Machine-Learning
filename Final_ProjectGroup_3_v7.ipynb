{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0ff800e9",
   "metadata": {},
   "source": [
    "# CPE 695 - Applied A.I. Final Project Code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fab0e308",
   "metadata": {},
   "source": [
    "# Setting up the Variables & Reading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f10187e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished reading the \"SeoulBikeData.csv\" file!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Rented Bike Count</th>\n",
       "      <th>Hour</th>\n",
       "      <th>Temperature(°C)</th>\n",
       "      <th>Humidity(%)</th>\n",
       "      <th>Wind speed (m/s)</th>\n",
       "      <th>Visibility (10m)</th>\n",
       "      <th>Dew point temperature(°C)</th>\n",
       "      <th>Solar Radiation (MJ/m2)</th>\n",
       "      <th>Rainfall(mm)</th>\n",
       "      <th>Snowfall (cm)</th>\n",
       "      <th>Seasons</th>\n",
       "      <th>Holiday</th>\n",
       "      <th>Functioning Day</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>01/12/2017</td>\n",
       "      <td>254</td>\n",
       "      <td>0</td>\n",
       "      <td>-5.2</td>\n",
       "      <td>37</td>\n",
       "      <td>2.2</td>\n",
       "      <td>2000</td>\n",
       "      <td>-17.6</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Winter</td>\n",
       "      <td>No Holiday</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>01/12/2017</td>\n",
       "      <td>204</td>\n",
       "      <td>1</td>\n",
       "      <td>-5.5</td>\n",
       "      <td>38</td>\n",
       "      <td>0.8</td>\n",
       "      <td>2000</td>\n",
       "      <td>-17.6</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Winter</td>\n",
       "      <td>No Holiday</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>01/12/2017</td>\n",
       "      <td>173</td>\n",
       "      <td>2</td>\n",
       "      <td>-6.0</td>\n",
       "      <td>39</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2000</td>\n",
       "      <td>-17.7</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Winter</td>\n",
       "      <td>No Holiday</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>01/12/2017</td>\n",
       "      <td>107</td>\n",
       "      <td>3</td>\n",
       "      <td>-6.2</td>\n",
       "      <td>40</td>\n",
       "      <td>0.9</td>\n",
       "      <td>2000</td>\n",
       "      <td>-17.6</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Winter</td>\n",
       "      <td>No Holiday</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>01/12/2017</td>\n",
       "      <td>78</td>\n",
       "      <td>4</td>\n",
       "      <td>-6.0</td>\n",
       "      <td>36</td>\n",
       "      <td>2.3</td>\n",
       "      <td>2000</td>\n",
       "      <td>-18.6</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Winter</td>\n",
       "      <td>No Holiday</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>01/12/2017</td>\n",
       "      <td>100</td>\n",
       "      <td>5</td>\n",
       "      <td>-6.4</td>\n",
       "      <td>37</td>\n",
       "      <td>1.5</td>\n",
       "      <td>2000</td>\n",
       "      <td>-18.7</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Winter</td>\n",
       "      <td>No Holiday</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>01/12/2017</td>\n",
       "      <td>181</td>\n",
       "      <td>6</td>\n",
       "      <td>-6.6</td>\n",
       "      <td>35</td>\n",
       "      <td>1.3</td>\n",
       "      <td>2000</td>\n",
       "      <td>-19.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Winter</td>\n",
       "      <td>No Holiday</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>01/12/2017</td>\n",
       "      <td>460</td>\n",
       "      <td>7</td>\n",
       "      <td>-7.4</td>\n",
       "      <td>38</td>\n",
       "      <td>0.9</td>\n",
       "      <td>2000</td>\n",
       "      <td>-19.3</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Winter</td>\n",
       "      <td>No Holiday</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>01/12/2017</td>\n",
       "      <td>930</td>\n",
       "      <td>8</td>\n",
       "      <td>-7.6</td>\n",
       "      <td>37</td>\n",
       "      <td>1.1</td>\n",
       "      <td>2000</td>\n",
       "      <td>-19.8</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Winter</td>\n",
       "      <td>No Holiday</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>01/12/2017</td>\n",
       "      <td>490</td>\n",
       "      <td>9</td>\n",
       "      <td>-6.5</td>\n",
       "      <td>27</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1928</td>\n",
       "      <td>-22.4</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Winter</td>\n",
       "      <td>No Holiday</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date  Rented Bike Count  Hour  Temperature(°C)  Humidity(%)  \\\n",
       "0  01/12/2017                254     0             -5.2           37   \n",
       "1  01/12/2017                204     1             -5.5           38   \n",
       "2  01/12/2017                173     2             -6.0           39   \n",
       "3  01/12/2017                107     3             -6.2           40   \n",
       "4  01/12/2017                 78     4             -6.0           36   \n",
       "5  01/12/2017                100     5             -6.4           37   \n",
       "6  01/12/2017                181     6             -6.6           35   \n",
       "7  01/12/2017                460     7             -7.4           38   \n",
       "8  01/12/2017                930     8             -7.6           37   \n",
       "9  01/12/2017                490     9             -6.5           27   \n",
       "\n",
       "   Wind speed (m/s)  Visibility (10m)  Dew point temperature(°C)  \\\n",
       "0               2.2              2000                      -17.6   \n",
       "1               0.8              2000                      -17.6   \n",
       "2               1.0              2000                      -17.7   \n",
       "3               0.9              2000                      -17.6   \n",
       "4               2.3              2000                      -18.6   \n",
       "5               1.5              2000                      -18.7   \n",
       "6               1.3              2000                      -19.5   \n",
       "7               0.9              2000                      -19.3   \n",
       "8               1.1              2000                      -19.8   \n",
       "9               0.5              1928                      -22.4   \n",
       "\n",
       "   Solar Radiation (MJ/m2)  Rainfall(mm)  Snowfall (cm) Seasons     Holiday  \\\n",
       "0                     0.00           0.0            0.0  Winter  No Holiday   \n",
       "1                     0.00           0.0            0.0  Winter  No Holiday   \n",
       "2                     0.00           0.0            0.0  Winter  No Holiday   \n",
       "3                     0.00           0.0            0.0  Winter  No Holiday   \n",
       "4                     0.00           0.0            0.0  Winter  No Holiday   \n",
       "5                     0.00           0.0            0.0  Winter  No Holiday   \n",
       "6                     0.00           0.0            0.0  Winter  No Holiday   \n",
       "7                     0.00           0.0            0.0  Winter  No Holiday   \n",
       "8                     0.01           0.0            0.0  Winter  No Holiday   \n",
       "9                     0.23           0.0            0.0  Winter  No Holiday   \n",
       "\n",
       "  Functioning Day  \n",
       "0             Yes  \n",
       "1             Yes  \n",
       "2             Yes  \n",
       "3             Yes  \n",
       "4             Yes  \n",
       "5             Yes  \n",
       "6             Yes  \n",
       "7             Yes  \n",
       "8             Yes  \n",
       "9             Yes  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Importing the libraries\n",
    "\n",
    "# Turning off warnings\n",
    "# https://queirozf.com/entries/suppressing-ignoring-warnings-in-python-reference-and-examples\n",
    "# at the top of the file, before other imports\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "# no warnings will be printed from now on\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pandas\n",
    "from sklearn.metrics import mean_squared_error # does the mean squared error calculations\n",
    "from numpy.linalg import inv # Takes the inverse of a matrix\n",
    "from sklearn.model_selection import train_test_split # Splits the Training Data and Test Data\n",
    "np.seterr(all='ignore') # overflow encountered in square python. Ignores errors \n",
    "from sklearn.linear_model import LinearRegression # linear regression algorithm class\n",
    "from sklearn.tree import DecisionTreeClassifier # can use decision trees with this for Classification\n",
    "from sklearn.tree import DecisionTreeRegressor # can use decision trees with this, for regression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.tree import export_graphviz # plots trees\n",
    "from sklearn import tree # trees\n",
    "from sklearn.tree import export_graphviz # used for graphing trees\n",
    "import graphviz # used for graphing trees\n",
    "import pydotplus # used for graphing dot files from graphviz into png\n",
    "import io # used saving dot text into a string text input stream\n",
    "from sklearn.model_selection import GridSearchCV # for pruning trees\n",
    "from sklearn.metrics import classification_report # for generating classification reports for accuracy\n",
    "from sklearn.ensemble import RandomForestClassifier # random forest trees classifier\n",
    "from sklearn.ensemble import RandomForestRegressor # random forest trees regression\n",
    "from sklearn.metrics import confusion_matrix # computes confusion_matrix\n",
    "from sklearn.neural_network import MLPClassifier  # ANNs Classification\n",
    "from sklearn.neural_network import MLPRegressor # ANN Regression\n",
    "from sklearn.datasets import make_classification  # ANNs\n",
    "from sklearn.metrics import accuracy_score # calculates accuracy scores\n",
    "from sklearn import preprocessing\n",
    "from sklearn.ensemble import BaggingRegressor\n",
    "from sklearn import preprocessing \n",
    "import sklearn.metrics as sm # for calculating R2 score\n",
    "\n",
    "# style of the plot grid\n",
    "plt.style.use('seaborn-whitegrid')\n",
    "\n",
    "# Read CSV File - researched online on how to use proper methods for reading CSV files\n",
    "# https://www.kite.com/python/answers/how-to-set-column-names-when-importing-a-csv-into-a-pandas-dataframe-in-python\n",
    "# Headers list: Date, Rented Bike Count, Hour, Temperature(°C), Humidity(%), Wind speed (m/s), Visibility (10m), \n",
    "#               Dew point temperature(°C), Solar Radiation (MJ/m2), Rainfall(mm), Snowfall (cm), Seasons, \n",
    "#               Holiday, Functioning Day\n",
    "# Step 1: set up headers information\n",
    "headers_list = [\"Date\", \"Rented Bike Count\", \"Hour\", \"Temperature(°C)\", \"Humidity(%)\", \n",
    "                \"Wind speed (m/s)\", \"Visibility (10m)\", \"Dew point temperature(°C)\", \n",
    "                \"Solar Radiation (MJ/m2)\", \"Rainfall(mm)\", \"Snowfall (cm)\", \"Seasons\", \n",
    "                \"Holiday\", \"Functioning Day\"\n",
    "               ]\n",
    "\n",
    "# Step 2: use Pandas read_csv function and populate a variable with the csv data. \n",
    "# https://stackoverflow.com/questions/54304551/python-csv-file-reading-turning-the-first-row-into-column-headers-nextreader\n",
    "# Skip the first row, since it's a header\n",
    "seoulbike_file_prime = pandas.read_csv('SeoulBikeData.csv', names=headers_list, skiprows=[0])\n",
    "print('Finished reading the \"SeoulBikeData.csv\" file!')\n",
    "\n",
    "seoulbike_file_prime.head(10) # prints the table's first 10 rows as a sample in a nice format. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22ce2276",
   "metadata": {},
   "source": [
    "# STEP 0: Functions and Regression Model Set-Up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "21b75a75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a function to automatically get the predictions of the Linear Regression\n",
    "def get_Linear_Reg_Predictions(X_train_def, X_test_def, y_train_def, bagging_switch):\n",
    "    #https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html\n",
    "        \n",
    "    # Linear Regressor \n",
    "    Linear_Regressor = LinearRegression()\n",
    "    \n",
    "    Bagged_Linear_Regressor = BaggingRegressor(base_estimator=Linear_Regressor, n_estimators=10, random_state=0)\n",
    "        \n",
    "    if (bagging_switch == True):\n",
    "        # Fit the X and Y training data\n",
    "        Linear_Regressor_Train = Bagged_Linear_Regressor.fit(X_train_def, y_train_def)\n",
    "    elif (bagging_switch == False):\n",
    "        # Fit the X and Y training data\n",
    "        Linear_Regressor_Train = Linear_Regressor.fit(X_train_def, y_train_def)\n",
    "    \n",
    "    # Predict the Results\n",
    "    Linear_Regressor_Predictions = Linear_Regressor_Train.predict(X_test_def)\n",
    "    \n",
    "    return Linear_Regressor_Predictions\n",
    "\n",
    "# define a function to automatically get the GridSearchCV Parameters for Trees\n",
    "def get_tree_params(X_train_def, X_test_def, y_train_def):\n",
    "    \n",
    "     # GridSearchCV Parameter Estimation\n",
    "    params = {'max_leaf_nodes': list(range(2, 100)), 'max_depth': list(range(2, 100))}\n",
    "    grid_search_cv = GridSearchCV(DecisionTreeRegressor(random_state=42), params, verbose=1, n_jobs=-1, cv=3)\n",
    "    \n",
    "    # fit the training data using GridSearchCV()\n",
    "    grid_search_cv.fit(X_train_def, y_train_def)\n",
    "    # finding the max parameter for max_leaf_nodes\n",
    "    grid_search_cv_best_estimator = grid_search_cv.best_estimator_\n",
    "    \n",
    "    # extracting max_leaf_nodes out of the variable\n",
    "    max_leaf_nodes_out = grid_search_cv_best_estimator.get_params(deep=True)['max_leaf_nodes']\n",
    "    max_depth_out = grid_search_cv_best_estimator.get_params(deep=True)['max_depth']\n",
    "    \n",
    "    return max_leaf_nodes_out, max_depth_out\n",
    "\n",
    "# define a function to automatically get the predictions of the Decision Tree\n",
    "def get_Decision_Tree_Predictions(X_train_def, X_test_def, y_train_def, max_leaf_nodes, max_depth, bagging_switch):\n",
    "    #https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeRegressor.html#sklearn.tree.DecisionTreeRegressor\n",
    "    \n",
    "    # Create a Decision Tree  \n",
    "    Decision_Tree_Regressor = DecisionTreeRegressor(\n",
    "                                    max_leaf_nodes = max_leaf_nodes, \n",
    "                                    max_depth = max_depth,\n",
    "                                    random_state = 0\n",
    "                                    )\n",
    "    Bagged_Decision_Tree_Regressor = BaggingRegressor(base_estimator=Decision_Tree_Regressor, n_estimators=10, random_state=0)\n",
    "    \n",
    "    if (bagging_switch == True):\n",
    "        # Fit the X and Y training data\n",
    "        Decision_Tree_Regressor_Train = Bagged_Decision_Tree_Regressor.fit(X_train_def, y_train_def)\n",
    "    elif (bagging_switch == False):\n",
    "        # Fit the X and Y training data\n",
    "        Decision_Tree_Regressor_Train = Decision_Tree_Regressor.fit(X_train_def, y_train_def)\n",
    "    \n",
    "    # Predict the Results\n",
    "    Decision_Tree_Regressor_Predictions = Decision_Tree_Regressor_Train.predict(X_test_def)\n",
    "    \n",
    "    return Decision_Tree_Regressor_Predictions\n",
    "\n",
    "# define a function to automatically get the predictions of the Random Forests\n",
    "def get_Random_Forests_Predictions(X_train_def, X_test_def, y_train_def, max_leaf_nodes, max_depth, bagging_switch):\n",
    "    # https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html\n",
    "    \n",
    "    # Create a Random Forests\n",
    "    Random_Forest_Regressor = RandomForestRegressor(\n",
    "                                    max_leaf_nodes = max_leaf_nodes, \n",
    "                                    max_depth = max_depth,\n",
    "                                    random_state = 0\n",
    "                                    )\n",
    "    Bagged_Random_Forests_Regressor = BaggingRegressor(base_estimator=Random_Forest_Regressor, n_estimators=10, random_state=0)\n",
    "\n",
    "    if (bagging_switch == True):\n",
    "        # Fit the X and Y training data\n",
    "        Random_Forest_Regressor_Train = Bagged_Random_Forests_Regressor.fit(X_train_def, y_train_def)\n",
    "    elif (bagging_switch == False):\n",
    "        # Fit the X and Y training data\n",
    "        Random_Forest_Regressor_Train = Random_Forest_Regressor.fit(X_train_def, y_train_def)\n",
    "    \n",
    "    # Predict the Results\n",
    "    Random_Forest_Regressor_Predictions = Random_Forest_Regressor_Train.predict(X_test_def)\n",
    "    \n",
    "    return Random_Forest_Regressor_Predictions    \n",
    "\n",
    "# define a function to automatically get the GridSearchCV Parameters for ANN\n",
    "def get_ANN_params(X_train_def, X_test_def, y_train_def):\n",
    "    \n",
    "     # GridSearchCV Parameter Estimation\n",
    "    params = {'hidden_neurons': list(range(0, 10)), \n",
    "              'alpha': list(range(0.0, 1.0)),\n",
    "              'learning_rate_init': list(range(0.0, 0.5)),\n",
    "              'momentum': list(range(0.0, 1.0)),\n",
    "             }\n",
    "    grid_search_cv = GridSearchCV(MLPRegressor(random_state=42), params, verbose=1, n_jobs=-1, cv=3)\n",
    "    \n",
    "    # fit the training data using GridSearchCV()\n",
    "    grid_search_cv.fit(X_train_def, y_train_def)\n",
    "    # finding the max parameter for max_leaf_nodes\n",
    "    grid_search_cv_best_estimator = grid_search_cv.best_estimator_\n",
    "    \n",
    "    # extracting max_leaf_nodes out of the variable\n",
    "    hidden_neurons_out = grid_search_cv_best_estimator.get_params(deep=True)['hidden_neurons']\n",
    "    alpha_out = grid_search_cv_best_estimator.get_params(deep=True)['alpha']\n",
    "    learning_rate_init_out = grid_search_cv_best_estimator.get_params(deep=True)['learning_rate_init']\n",
    "    momentum_out = grid_search_cv_best_estimator.get_params(deep=True)['momentum']\n",
    "    \n",
    "    return hidden_neurons_out, alpha_out, learning_rate_init_out, momentum_out\n",
    "\n",
    "# define a function to automatically get the predictions of the ANN's MLPs\n",
    "def get_ANN_Predictions(hidden_neurons, X_train_def, X_test_def, y_train_def, bagging_switch):\n",
    "    # Resource links:\n",
    "    # https://scikit-learn.org/stable/modules/neural_networks_supervised.html\n",
    "    # https://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPClassifier.html\n",
    "    # https://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPRegressor.html\n",
    "\n",
    "    # ANN - MLP Settings\n",
    "    Hidden_Layers = (hidden_neurons, hidden_neurons) # Needs to be a tuple for MLP Class - use 2 layers for this project\n",
    "    activation_setting = 'logistic' # the logistic sigmoid function, returns f(x) = 1 / (1 + exp(-x)).\n",
    "    #solver_setting = 'adam' # refers to a stochastic gradient-based optimizer proposed by Kingma, Diederik, and Jimmy Ba\n",
    "    solver_setting = 'sgd' # refers to stochastic gradient descent.\n",
    "    alpha_setting = 0.0000001 # L2 penalty (regularization term) parameter.\n",
    "    learning_rate_setting = 'constant' # 'constant' is a constant learning rate given by 'learning_rate_init'.\n",
    "    learning_rate_init_setting = 0.1 # The initial learning rate used. It controls the step-size in updating the weights.\n",
    "    momentum_setting = 0.5 # Momentum for gradient descent update. Should be between 0 and 1. Only used when solver=’sgd’.\n",
    "    #early_stopping_setting = True # f set to true, it will automatically set aside 10% of training data as validation \n",
    "                                  # and terminate training when validation score is not improving by at least tol for \n",
    "                                  # n_iter_no_change consecutive epochs.\n",
    "\n",
    "    # Create a Multi-Layer Perceptron Regressor \n",
    "    MLP_Regressor = MLPRegressor(hidden_layer_sizes = Hidden_Layers, \n",
    "                                   #activation = activation_setting, # gives same result if this is turned on. Turned off\n",
    "                                   #solver = solver_setting,         # gives same result if this is turned on. Turned off\n",
    "                                   alpha = alpha_setting, \n",
    "                                   learning_rate = learning_rate_setting, \n",
    "                                   learning_rate_init = learning_rate_init_setting,\n",
    "                                   momentum = momentum_setting,\n",
    "                                   #early_stopping = early_stopping_setting,\n",
    "                                   random_state=1, max_iter=2500\n",
    "                                  )\n",
    "    Bagged_MLP_Regressor = BaggingRegressor(base_estimator=MLP_Regressor, n_estimators=10, random_state=0)\n",
    "\n",
    "    if (bagging_switch == True):\n",
    "        # Fit the X and Y training data\n",
    "        MLP_Regressor_Train = Bagged_MLP_Regressor.fit(X_train_def, y_train_def)\n",
    "    elif (bagging_switch == False):\n",
    "        # Fit the X and Y training data\n",
    "        MLP_Regressor_Train = MLP_Regressor.fit(X_train_def, y_train_def)\n",
    "    \n",
    "    # Predict the Results\n",
    "    MLP_Regressor_Predictions = MLP_Regressor_Train.predict(X_test_def)\n",
    "    #print(\"MLP_Regressor_Predictions:\",MLP_Regressor_Predictions)\n",
    "    \n",
    "    return MLP_Regressor_Predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e6af313",
   "metadata": {},
   "source": [
    "# STEP 1: Clean Up Data (Encoding + Delete Unnecessary Rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bd97224d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before removal of unnecessary data: 8760\n",
      "After removal of unnecessary data: 8465\n",
      "Removed 295 rows!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rented Bike Count</th>\n",
       "      <th>Functioning Day</th>\n",
       "      <th>Seasons</th>\n",
       "      <th>Dew point temperature(°C)</th>\n",
       "      <th>Temperature(°C)</th>\n",
       "      <th>Humidity(%)</th>\n",
       "      <th>Rainfall(mm)</th>\n",
       "      <th>Visibility (10m)</th>\n",
       "      <th>Solar Radiation (MJ/m2)</th>\n",
       "      <th>Hour</th>\n",
       "      <th>Wind speed (m/s)</th>\n",
       "      <th>Holiday</th>\n",
       "      <th>Snowfall (cm)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>254</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>-17.6</td>\n",
       "      <td>-5.2</td>\n",
       "      <td>37</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>2.2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>204</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>-17.6</td>\n",
       "      <td>-5.5</td>\n",
       "      <td>38</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>173</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>-17.7</td>\n",
       "      <td>-6.0</td>\n",
       "      <td>39</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>107</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>-17.6</td>\n",
       "      <td>-6.2</td>\n",
       "      <td>40</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>3</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>78</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>-18.6</td>\n",
       "      <td>-6.0</td>\n",
       "      <td>36</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>4</td>\n",
       "      <td>2.3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>-18.7</td>\n",
       "      <td>-6.4</td>\n",
       "      <td>37</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>5</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>181</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>-19.5</td>\n",
       "      <td>-6.6</td>\n",
       "      <td>35</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>6</td>\n",
       "      <td>1.3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>460</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>-19.3</td>\n",
       "      <td>-7.4</td>\n",
       "      <td>38</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>7</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>930</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>-19.8</td>\n",
       "      <td>-7.6</td>\n",
       "      <td>37</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2000</td>\n",
       "      <td>0.01</td>\n",
       "      <td>8</td>\n",
       "      <td>1.1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>490</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>-22.4</td>\n",
       "      <td>-6.5</td>\n",
       "      <td>27</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1928</td>\n",
       "      <td>0.23</td>\n",
       "      <td>9</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Rented Bike Count  Functioning Day  Seasons  Dew point temperature(°C)  \\\n",
       "0                254                1        3                      -17.6   \n",
       "1                204                1        3                      -17.6   \n",
       "2                173                1        3                      -17.7   \n",
       "3                107                1        3                      -17.6   \n",
       "4                 78                1        3                      -18.6   \n",
       "5                100                1        3                      -18.7   \n",
       "6                181                1        3                      -19.5   \n",
       "7                460                1        3                      -19.3   \n",
       "8                930                1        3                      -19.8   \n",
       "9                490                1        3                      -22.4   \n",
       "\n",
       "   Temperature(°C)  Humidity(%)  Rainfall(mm)  Visibility (10m)  \\\n",
       "0             -5.2           37           0.0              2000   \n",
       "1             -5.5           38           0.0              2000   \n",
       "2             -6.0           39           0.0              2000   \n",
       "3             -6.2           40           0.0              2000   \n",
       "4             -6.0           36           0.0              2000   \n",
       "5             -6.4           37           0.0              2000   \n",
       "6             -6.6           35           0.0              2000   \n",
       "7             -7.4           38           0.0              2000   \n",
       "8             -7.6           37           0.0              2000   \n",
       "9             -6.5           27           0.0              1928   \n",
       "\n",
       "   Solar Radiation (MJ/m2)  Hour  Wind speed (m/s)  Holiday  Snowfall (cm)  \n",
       "0                     0.00     0               2.2        1            0.0  \n",
       "1                     0.00     1               0.8        1            0.0  \n",
       "2                     0.00     2               1.0        1            0.0  \n",
       "3                     0.00     3               0.9        1            0.0  \n",
       "4                     0.00     4               2.3        1            0.0  \n",
       "5                     0.00     5               1.5        1            0.0  \n",
       "6                     0.00     6               1.3        1            0.0  \n",
       "7                     0.00     7               0.9        1            0.0  \n",
       "8                     0.01     8               1.1        1            0.0  \n",
       "9                     0.23     9               0.5        1            0.0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# STEP 1: Clean up Data\n",
    "# Ignore Date. It is unimportant\n",
    "\n",
    "# Convert strings to discrete values\n",
    "le = preprocessing.LabelEncoder()\n",
    "\n",
    "le.fit(seoulbike_file_prime['Seasons'])\n",
    "seoulbike_file_prime['Seasons'] = le.transform(seoulbike_file_prime['Seasons'])\n",
    "\n",
    "le.fit(seoulbike_file_prime['Holiday'])\n",
    "seoulbike_file_prime['Holiday'] = le.transform(seoulbike_file_prime['Holiday'])\n",
    "\n",
    "le.fit(seoulbike_file_prime['Functioning Day'])\n",
    "seoulbike_file_prime['Functioning Day'] = le.transform(seoulbike_file_prime['Functioning Day'])\n",
    "\n",
    "# initialize the seoulbike data - used as a way to prevent overwrites on existing copies\n",
    "seoulbike_file = seoulbike_file_prime\n",
    "\n",
    "# This section chooses the most impactful columns. Trims down the excess noise\n",
    "# Tier List of Most Impactful Columns\n",
    "# 1. Functioning Day\n",
    "# 2. Season\n",
    "# 3. Dew point temperature(°C)\n",
    "# 4. Temperature(°C)\n",
    "# 5. Humidity(%)\n",
    "# 6. Rainfall(mm)\n",
    "refined_seoulbike_columns = [\"Rented Bike Count\", \n",
    "                             \"Functioning Day\", \n",
    "                             \"Seasons\", \"Dew point temperature(°C)\",\n",
    "                             \"Temperature(°C)\", \"Humidity(%)\", \"Rainfall(mm)\", \n",
    "                             \n",
    "                             \"Visibility (10m)\", \"Solar Radiation (MJ/m2)\", \"Hour\", \n",
    "                             \"Wind speed (m/s)\", \"Holiday\", \"Snowfall (cm)\"\n",
    "                            ]\n",
    "refined_seoulbike = seoulbike_file[refined_seoulbike_columns]\n",
    "before_shape = refined_seoulbike.shape[0]\n",
    "print(\"Before removal of unnecessary data:\",before_shape)\n",
    "\n",
    "\n",
    "\n",
    "# REMOVING OUTLIERS/UNNECESSARY DATA\n",
    "# Remove rows with 0 rented bikes. Remove the usage of Functioning Day\n",
    "refined_seoulbike = refined_seoulbike[refined_seoulbike[\"Rented Bike Count\"]>0]\n",
    "\n",
    "\n",
    "\n",
    "after_shape = refined_seoulbike.shape[0]\n",
    "print(\"After removal of unnecessary data:\",refined_seoulbike.shape[0])\n",
    "print(\"Removed\",(before_shape-after_shape), \"rows!\")\n",
    "\n",
    "refined_seoulbike.head(10) # prints the table's first 10 rows as a sample in a nice format."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfeb4b7c",
   "metadata": {},
   "source": [
    "# STEP 2: Splitting Data into Training/ Testing Dataset + NORMALIZATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8aac6793",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data is normalized by the use of Min-Max Normalization!\n",
      "\n",
      "Size of X_train: 6772 \tPercentage: 0.8\n",
      "Size of X_test : 1693 \tPercentage: 0.2\n",
      "Size of total independent_seoulbike(X): 8465\n",
      "\n",
      "Size of y_train: 6772 \tPercentage: 0.8\n",
      "Size of y_test : 1693 \tPercentage: 0.2\n",
      "Size of total dependent_seoulbike(Y): 8465\n",
      "\n",
      "The data is split close to how we want it. Close to 80% for Training, and 20% for Testing\n",
      "\n",
      "Sample data of first 3 rows of TRAINING DATASET. Just a preview of how it looks:\n",
      "=================================\n",
      "First 3 samples of X_train:\n",
      "        Seasons  Dew point temperature(°C)  Temperature(°C)  Humidity(%)  \\\n",
      "5564  0.666667                   0.872822         0.857394     0.520408   \n",
      "1467  1.000000                   0.451220         0.274648     0.846939   \n",
      "2229  0.333333                   0.547038         0.494718     0.530612   \n",
      "\n",
      "      Rainfall(mm)  Visibility (10m)  Solar Radiation (MJ/m2)      Hour  \\\n",
      "5564           0.0          1.000000                 0.019886  0.869565   \n",
      "1467           0.0          0.481500                 0.000000  0.130435   \n",
      "2229           0.0          0.920426                 0.000000  0.913043   \n",
      "\n",
      "      Wind speed (m/s)  Holiday  Snowfall (cm)  \n",
      "5564          0.297297      1.0       0.000000  \n",
      "1467          0.135135      1.0       0.397727  \n",
      "2229          0.297297      1.0       0.000000  \n",
      "\n",
      "First 3 samples of y_train:\n",
      "       Rented Bike Count\n",
      "5564               1888\n",
      "1467                 47\n",
      "2229                588\n",
      "=================================\n",
      "\n",
      "Sample data of first 3 rows of TESTING DATASET. Just a preview of how it looks:\n",
      "=================================\n",
      "First 3 samples of X_test:\n",
      "        Seasons  Dew point temperature(°C)  Temperature(°C)  Humidity(%)  \\\n",
      "3735  0.333333                   0.608319         0.720430     0.295918   \n",
      "2084  1.000000                   0.386482         0.317204     0.500000   \n",
      "7147  0.000000                   0.684575         0.627240     0.551020   \n",
      "\n",
      "      Rainfall(mm)  Visibility (10m)  Solar Radiation (MJ/m2)      Hour  \\\n",
      "3735           0.0          0.935983                 0.816817  0.652174   \n",
      "2084           0.0          0.836345                 0.000000  0.869565   \n",
      "7147           0.0          1.000000                 0.003003  0.826087   \n",
      "\n",
      "      Wind speed (m/s)  Holiday  Snowfall (cm)  \n",
      "3735          0.652778      1.0            0.0  \n",
      "2084          0.388889      1.0            0.0  \n",
      "7147          0.375000      0.0            0.0  \n",
      "\n",
      "First 3 samples of y_test:\n",
      "       Rented Bike Count\n",
      "3735               1837\n",
      "2084                232\n",
      "7147               1280\n",
      "=================================\n"
     ]
    }
   ],
   "source": [
    "# STEP 2: Creating Independent and Dependent Data\n",
    "# Create a subset of the table with indepdendent variables and dependent variables\n",
    "subset_list_independent = [#\"Functioning Day\",\n",
    "                           \"Seasons\", \"Dew point temperature(°C)\",\n",
    "                           \"Temperature(°C)\", \"Humidity(%)\", \"Rainfall(mm)\", \n",
    "                           \n",
    "                           \"Visibility (10m)\", \"Solar Radiation (MJ/m2)\", \n",
    "                           \"Hour\",\n",
    "                           \"Wind speed (m/s)\", \n",
    "                           \"Holiday\", \n",
    "                           \"Snowfall (cm)\"\n",
    "                          ]\n",
    "subset_list_dependent = ['Rented Bike Count']\n",
    "independent_seoulbike = refined_seoulbike[subset_list_independent]\n",
    "dependent_seoulbike = refined_seoulbike[subset_list_dependent]\n",
    "\n",
    "# STEP 2.1: # Take a random 80% samples for training and the rest 20% for test.\n",
    "X_train, X_test, y_train, y_test = train_test_split(independent_seoulbike, dependent_seoulbike, test_size=0.2)\n",
    "\n",
    "# STEP 2.2 NORMALIZE TRAINING AND TESTING DATA INDIVIDUALLY\n",
    "# https://stackoverflow.com/questions/49444262/normalize-data-before-or-after-split-of-training-and-testing-data\n",
    "\n",
    "bool_MEAN_NORMALIZATION = False # This makes it so that the data is normalized by mean value\n",
    "bool_MIN_MAX_NORMALIZATION = True # This makes it so that the data is normalized by min-max values\n",
    "\n",
    "if (bool_MEAN_NORMALIZATION == True):\n",
    "    print(\"Data is normalized by the use of Mean Normalization!\")\n",
    "    X_train=(X_train-X_train.mean())/X_train.std()\n",
    "    X_test=(X_test-X_test.mean())/X_test.std()\n",
    "elif (bool_MIN_MAX_NORMALIZATION == True):\n",
    "    print(\"Data is normalized by the use of Min-Max Normalization!\")\n",
    "    X_train=(X_train-X_train.min())/(X_train.max()-X_train.min())\n",
    "    X_test=(X_test-X_test.min())/(X_test.max()-X_test.min())\n",
    "else:\n",
    "    print(\"Data is not normalized! Warning! If intentional, proceed forward!\")\n",
    "\n",
    "# STEP 2.3: Print Split Data\n",
    "# Print all the details of the new datasets formed\n",
    "print(\"\\nSize of X_train:\",len(X_train), \"\\tPercentage:\", round( len(X_train)/len(independent_seoulbike), 2)  )\n",
    "print(\"Size of X_test :\" ,len(X_test) ,\"\\tPercentage:\", round( len(X_test)/len(independent_seoulbike), 2)  )\n",
    "print(\"Size of total independent_seoulbike(X):\",len(independent_seoulbike))\n",
    "print(\"\")\n",
    "print(\"Size of y_train:\",len(y_train), \"\\tPercentage:\", round( len(y_train)/len(dependent_seoulbike), 2)  )\n",
    "print(\"Size of y_test :\" ,len(y_test) ,\"\\tPercentage:\", round( len(y_test)/len(dependent_seoulbike), 2)  )\n",
    "print(\"Size of total dependent_seoulbike(Y):\",len(dependent_seoulbike))\n",
    "\n",
    "print(\"\\nThe data is split close to how we want it. Close to 80% for Training, and 20% for Testing\\n\")\n",
    "\n",
    "print(\"Sample data of first 3 rows of TRAINING DATASET. Just a preview of how it looks:\")\n",
    "print('=================================')\n",
    "print(\"First 3 samples of X_train:\\n\",X_train.head(3))\n",
    "print(\"\\nFirst 3 samples of y_train:\\n\",y_train.head(3))\n",
    "print('=================================\\n')\n",
    "print(\"Sample data of first 3 rows of TESTING DATASET. Just a preview of how it looks:\")\n",
    "print('=================================')\n",
    "print(\"First 3 samples of X_test:\\n\",X_test.head(3))\n",
    "print(\"\\nFirst 3 samples of y_test:\\n\",y_test.head(3))\n",
    "print('=================================')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b2eab32",
   "metadata": {},
   "source": [
    "# STEP 3: Train Regression Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "213cf2f0",
   "metadata": {},
   "source": [
    "### Step 3.1 Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "06d49589",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear_Regressor_Predictions\n",
      "Index\tPrediction\n",
      "0 \t 1289.6846834242515\n",
      "1 \t 616.1775829545924\n",
      "2 \t 1230.2978020600744\n",
      "3 \t 663.8826135140354\n",
      "4 \t 724.3531577223788\n",
      "\n",
      "Bagged Linear_Regressor_Predictions\n",
      "Index\tPrediction\n",
      "0 \t 1287.4660777725735\n",
      "1 \t 606.8502894906035\n",
      "2 \t 1215.290231807764\n",
      "3 \t 664.7950408909444\n",
      "4 \t 719.616751090122\n",
      "Mean Squared Error of Linear Regressor: 187350.9506241019\n",
      "Mean Squared Error of Bagged Linear Regressor: 188696.30419694906\n"
     ]
    }
   ],
   "source": [
    "print_switch = True\n",
    "# https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html\n",
    "\n",
    "# Unbagged Linear Regressor\n",
    "Linear_Regressor_Predictions = np.abs(get_Linear_Reg_Predictions(X_train, X_test, y_train, False))\n",
    "\n",
    "# Bagged Linear Regressor\n",
    "Bagged_Linear_Regressor_Predictions = np.abs(get_Linear_Reg_Predictions(X_train, X_test, y_train, True))\n",
    "\n",
    "if (print_switch):\n",
    "    print(\"Linear_Regressor_Predictions\")\n",
    "    print(\"Index\\tPrediction\")\n",
    "    for i in range (5):\n",
    "        print(i,\"\\t\",Linear_Regressor_Predictions[i][0])\n",
    "    print(\"\")\n",
    "    print(\"Bagged Linear_Regressor_Predictions\")\n",
    "    print(\"Index\\tPrediction\")\n",
    "    for i in range (5):\n",
    "        print(i,\"\\t\",Bagged_Linear_Regressor_Predictions[i])\n",
    "\n",
    "MSE_Linear_Regressor = mean_squared_error(y_true=y_test, y_pred=Linear_Regressor_Predictions)\n",
    "print(\"Mean Squared Error of Linear Regressor:\",MSE_Linear_Regressor)\n",
    "Bagged_MSE_Linear_Regressor = mean_squared_error(y_true=y_test, y_pred=Bagged_Linear_Regressor_Predictions)\n",
    "print(\"Mean Squared Error of Bagged Linear Regressor:\",Bagged_MSE_Linear_Regressor)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae16323c",
   "metadata": {},
   "source": [
    "### Step 3.2 Decision Tree Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3acf2308",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 9604 candidates, totalling 28812 fits\n",
      "GridSearchCV Parameter Estimations using Decision Classifier\n",
      "This code takes a lot of time, please wait...\n",
      "\tmax_leaf_nodes_out: 80\n",
      "\tmax_depth_out: 10\n",
      "\n",
      "Decision_Tree_Regressor_Predictions\n",
      "Index\tPrediction\n",
      "0 \t 1428.1785714285713\n",
      "1 \t 255.18199608610567\n",
      "2 \t 1480.4202898550725\n",
      "3 \t 601.8720930232558\n",
      "4 \t 977.1967213114754\n",
      "\n",
      "Bagged Decision_Tree_Regressor_Predictions\n",
      "Index\tPrediction\n",
      "0 \t 1461.0769604487741\n",
      "1 \t 269.5003038045108\n",
      "2 \t 1691.8685188820546\n",
      "3 \t 635.849009534161\n",
      "4 \t 975.2468103562971\n",
      "Mean Squared Error of Decision Tree Regressor: 84448.63677685935\n",
      "Mean Squared Error of Bagged Decision Tree Regressor: 69566.01340604988\n"
     ]
    }
   ],
   "source": [
    "print_switch = True\n",
    "\n",
    "# Get Paramters using GridSearchCV - Use this for Decision Tree and Random Forests\n",
    "max_leaf_nodes_out, max_depth_out = get_tree_params(X_train, X_test, y_train)\n",
    "if (print_switch):\n",
    "    print(\"GridSearchCV Parameter Estimations using Decision Classifier\")\n",
    "    print(\"This code takes a lot of time, please wait...\")\n",
    "    print(\"\\tmax_leaf_nodes_out:\",max_leaf_nodes_out)\n",
    "    print(\"\\tmax_depth_out:\",max_depth_out)\n",
    "    print(\"\")\n",
    "\n",
    "# https://scikit-learn.org/stable/auto_examples/tree/plot_tree_regression.html\n",
    "\n",
    "# Decision Tree Regressor\n",
    "Decision_Tree_Regressor_Predictions = np.abs(get_Decision_Tree_Predictions(X_train, X_test, y_train, max_leaf_nodes_out, max_depth_out, False))\n",
    "\n",
    "# Bagged Decision Tree Regressor\n",
    "Bagged_Decision_Tree_Regressor_Predictions = np.abs(get_Decision_Tree_Predictions(X_train, X_test, y_train, max_leaf_nodes_out, max_depth_out, True))\n",
    "\n",
    "if (print_switch):\n",
    "    print(\"Decision_Tree_Regressor_Predictions\")\n",
    "    print(\"Index\\tPrediction\")\n",
    "    for i in range (5):\n",
    "        print(i,\"\\t\",Decision_Tree_Regressor_Predictions[i])\n",
    "    print(\"\")\n",
    "    print(\"Bagged Decision_Tree_Regressor_Predictions\")\n",
    "    print(\"Index\\tPrediction\")\n",
    "    for i in range (5):\n",
    "        print(i,\"\\t\",Bagged_Decision_Tree_Regressor_Predictions[i])\n",
    "        \n",
    "MSE_Decision_Tree_Regressor = mean_squared_error(y_true=y_test, y_pred=Decision_Tree_Regressor_Predictions)\n",
    "print(\"Mean Squared Error of Decision Tree Regressor:\",MSE_Decision_Tree_Regressor)\n",
    "Bagged_MSE_Decision_Tree_Regressor = mean_squared_error(y_true=y_test, y_pred=Bagged_Decision_Tree_Regressor_Predictions)\n",
    "print(\"Mean Squared Error of Bagged Decision Tree Regressor:\",Bagged_MSE_Decision_Tree_Regressor)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "054ffbb3",
   "metadata": {},
   "source": [
    "### Step 3.3 Random Forests Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "032e1b61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using same parameters as DecisionTreeRegressor\n",
      "\n",
      "Random_Forest_Regressor_Predictions\n",
      "Index\tPrediction\n",
      "0 \t 1396.5332365061302\n",
      "1 \t 263.16010439237004\n",
      "2 \t 1630.5524379275757\n",
      "3 \t 610.5209257124841\n",
      "4 \t 985.0278434191003\n",
      "\n",
      "Bagged Random_Forest_Regressor_Predictions\n",
      "Index\tPrediction\n",
      "0 \t 1380.1201406328917\n",
      "1 \t 274.29637358431563\n",
      "2 \t 1637.7167116698706\n",
      "3 \t 591.0101322849046\n",
      "4 \t 996.6043666642884\n",
      "Mean Squared Error of Random Forest Regressor: 68243.9963392076\n",
      "Mean Squared Error of Bagged Random Forest Regressor: 65897.9893130154\n"
     ]
    }
   ],
   "source": [
    "print_switch = True\n",
    "# https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html\n",
    "\n",
    "# Random Forest Regressor\n",
    "Random_Forest_Regressor_Predictions = np.abs(get_Random_Forests_Predictions(X_train, X_test, y_train, max_leaf_nodes_out, max_depth_out, False))\n",
    "\n",
    "# Bagged Random Forest Regressor\n",
    "Bagged_Random_Forest_Regressor_Predictions = np.abs(get_Random_Forests_Predictions(X_train, X_test, y_train, max_leaf_nodes_out, max_depth_out, True))\n",
    "\n",
    "if (print_switch):\n",
    "    print(\"Using same parameters as DecisionTreeRegressor\\n\")\n",
    "    print(\"Random_Forest_Regressor_Predictions\")\n",
    "    print(\"Index\\tPrediction\")\n",
    "    for i in range (5):\n",
    "        print(i,\"\\t\",Random_Forest_Regressor_Predictions[i])\n",
    "    print(\"\")\n",
    "    print(\"Bagged Random_Forest_Regressor_Predictions\")\n",
    "    print(\"Index\\tPrediction\")\n",
    "    for i in range (5):\n",
    "        print(i,\"\\t\",Bagged_Random_Forest_Regressor_Predictions[i])\n",
    "\n",
    "MSE_Random_Forest_Regressor = mean_squared_error(y_true=y_test, y_pred=Random_Forest_Regressor_Predictions)\n",
    "print(\"Mean Squared Error of Random Forest Regressor:\",MSE_Random_Forest_Regressor)\n",
    "Bagged_MSE_Random_Forest_Regressor = mean_squared_error(y_true=y_test, y_pred=Bagged_Random_Forest_Regressor_Predictions)\n",
    "print(\"Mean Squared Error of Bagged Random Forest Regressor:\",Bagged_MSE_Random_Forest_Regressor)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb761d6c",
   "metadata": {},
   "source": [
    "### Step 3.4 Artificial Neural Networks Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a7f48ac5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP_Regressor_Predictions\n",
      "Index\tPrediction\n",
      "0 \t 1313.0839519667709\n",
      "1 \t 313.28750690177264\n",
      "2 \t 1447.4840384113518\n",
      "3 \t 569.8426484804546\n",
      "4 \t 816.1318674861949\n",
      "\n",
      "Bagged MLP_Regressor_Predictions\n",
      "Index\tPrediction\n",
      "0 \t 1307.8367983533167\n",
      "1 \t 318.5160700771663\n",
      "2 \t 1444.321541725831\n",
      "3 \t 554.267114627613\n",
      "4 \t 842.3907314695264\n",
      "Mean Squared Error of MLP Regressor: 161488.62129703877\n",
      "Mean Squared Error of Bagged MLP Regressor: 160252.64662896984\n"
     ]
    }
   ],
   "source": [
    "print_switch = True\n",
    "# https://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPRegressor.html\n",
    "\n",
    "# MLP Regressor\n",
    "MLP_Regressor_Predictions = np.abs(get_ANN_Predictions(10, X_train, X_test, y_train, False))\n",
    "\n",
    "# Bagged MLP Regressor\n",
    "Bagged_MLP_Regressor_Predictions = np.abs(get_ANN_Predictions(10, X_train, X_test, y_train, True))\n",
    "\n",
    "if (print_switch):\n",
    "    print(\"MLP_Regressor_Predictions\")\n",
    "    print(\"Index\\tPrediction\")\n",
    "    for i in range (5):\n",
    "        print(i,\"\\t\",MLP_Regressor_Predictions[i])\n",
    "    print(\"\")\n",
    "    print(\"Bagged MLP_Regressor_Predictions\")\n",
    "    print(\"Index\\tPrediction\")\n",
    "    for i in range (5):\n",
    "        print(i,\"\\t\",Bagged_MLP_Regressor_Predictions[i])\n",
    "\n",
    "MSE_MLP_Regressor = mean_squared_error(y_true=y_test, y_pred=MLP_Regressor_Predictions)\n",
    "print(\"Mean Squared Error of MLP Regressor:\",MSE_MLP_Regressor)\n",
    "Bagged_MSE_MLP_Regressor = mean_squared_error(y_true=y_test, y_pred=Bagged_MLP_Regressor_Predictions)\n",
    "print(\"Mean Squared Error of Bagged MLP Regressor:\",Bagged_MSE_MLP_Regressor)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b894a46a",
   "metadata": {},
   "source": [
    "# STEP 4: Combine Regression Models with Ensemble Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d33532e3",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Regular MSE:\n",
      "Mean Squared Error of Linear Regressor: 187350.9506241019\n",
      "Mean Squared Error of Decision Tree Regressor: 84448.63677685935\n",
      "Mean Squared Error of Random Forest Regressor: 68243.9963392076\n",
      "Mean Squared Error of MLP Regressor: 161488.62129703877\n",
      "Bagged MSE:\n",
      "Mean Squared Error of Bagged Linear Regressor: 188696.30419694906\n",
      "Mean Squared Error of Bagged Decision Tree Regressor: 69566.01340604988\n",
      "Mean Squared Error of Bagged Random Forest Regressor: 65897.9893130154\n",
      "Mean Squared Error of Bagged MLP Regressor: 160252.64662896984\n",
      "\n",
      "\n",
      "Fusion: Average of Predictions\n",
      "Index\tPrediction\n",
      "0 \t 1357.0\n",
      "1 \t 362.0\n",
      "2 \t 1447.0\n",
      "3 \t 612.0\n",
      "4 \t 876.0\n",
      "\n",
      "Fusion: Bagged Average of Predictions\n",
      "Index\tPrediction\n",
      "0 \t 1359.0\n",
      "1 \t 367.0\n",
      "2 \t 1497.0\n",
      "3 \t 611.0\n",
      "4 \t 883.0\n",
      "\n",
      "Mean Squared Error of Averaged Regression: 95568\n",
      "Mean Squared Error of Bagged Averaged Regression: 93729\n",
      "\n",
      "Regression Score of Averaged Regression: 77.01 %\n",
      "Regression Score of Bagged Averaged Regression: 77.45 %\n"
     ]
    }
   ],
   "source": [
    "print_switch = True\n",
    "\n",
    "# Bagging/Pasting - Implement in future\n",
    "# https://machinelearningmastery.com/ensemble-machine-learning-algorithms-python-scikit-learn/\n",
    "\n",
    "print(\"Regular MSE:\")\n",
    "print(\"Mean Squared Error of Linear Regressor:\",MSE_Linear_Regressor)\n",
    "print(\"Mean Squared Error of Decision Tree Regressor:\",MSE_Decision_Tree_Regressor)\n",
    "print(\"Mean Squared Error of Random Forest Regressor:\",MSE_Random_Forest_Regressor)\n",
    "print(\"Mean Squared Error of MLP Regressor:\",MSE_MLP_Regressor)\n",
    "print(\"Bagged MSE:\")\n",
    "print(\"Mean Squared Error of Bagged Linear Regressor:\",Bagged_MSE_Linear_Regressor)\n",
    "print(\"Mean Squared Error of Bagged Decision Tree Regressor:\",Bagged_MSE_Decision_Tree_Regressor)\n",
    "print(\"Mean Squared Error of Bagged Random Forest Regressor:\",Bagged_MSE_Random_Forest_Regressor)\n",
    "print(\"Mean Squared Error of Bagged MLP Regressor:\",Bagged_MSE_MLP_Regressor)\n",
    "print(\"\\n\")\n",
    "Total_Number_of_Regressors = 4 # useful for calculating averages\n",
    "\n",
    "# Ensemble Fusion Methods\n",
    "\n",
    "# Fusion - Average of Regressions - Regular\n",
    "average_regression = np.zeros(y_test.size)\n",
    "for i in range (y_test.size):\n",
    "    lin_r = Linear_Regressor_Predictions[i][0]\n",
    "    tree_r = Decision_Tree_Regressor_Predictions[i]\n",
    "    rand_tree_r = Random_Forest_Regressor_Predictions[i]\n",
    "    mlp_r = MLP_Regressor_Predictions[i]\n",
    "    \n",
    "    sum_reg =  (lin_r + tree_r + rand_tree_r + mlp_r)\n",
    "    average_regression[i] = round(sum_reg/Total_Number_of_Regressors)\n",
    "\n",
    "# Fusion - Average of Regressions - Bagged\n",
    "bagged_average_regression = np.zeros(y_test.size)\n",
    "for i in range (y_test.size):\n",
    "    lin_r = Bagged_Linear_Regressor_Predictions[i]\n",
    "    tree_r = Bagged_Decision_Tree_Regressor_Predictions[i]\n",
    "    rand_tree_r = Bagged_Random_Forest_Regressor_Predictions[i]\n",
    "    mlp_r = Bagged_MLP_Regressor_Predictions[i]\n",
    "    \n",
    "    sum_reg =  (lin_r + tree_r + rand_tree_r + mlp_r)\n",
    "    bagged_average_regression[i] = round(sum_reg/Total_Number_of_Regressors)\n",
    "\n",
    "if (print_switch):\n",
    "    print(\"Fusion: Average of Predictions\")\n",
    "    print(\"Index\\tPrediction\")\n",
    "    for i in range (5):\n",
    "        print(i,\"\\t\",average_regression[i])\n",
    "    print(\"\")\n",
    "    print(\"Fusion: Bagged Average of Predictions\")\n",
    "    print(\"Index\\tPrediction\")\n",
    "    for i in range (5):\n",
    "        print(i,\"\\t\",bagged_average_regression[i])\n",
    "        \n",
    "print(\"\")\n",
    "MSE_average_reg = mean_squared_error(y_true=y_test, y_pred=average_regression)\n",
    "print(\"Mean Squared Error of Averaged Regression:\",round(MSE_average_reg))\n",
    "Bagged_MSE_average_reg = mean_squared_error(y_true=y_test, y_pred=bagged_average_regression)\n",
    "print(\"Mean Squared Error of Bagged Averaged Regression:\", round(Bagged_MSE_average_reg))\n",
    "print(\"\")\n",
    "\n",
    "# Accuracy Report\n",
    "# https://subscription.packtpub.com/book/data/9781789808452/1/ch01lvl1sec12/computing-regression-accuracy\n",
    "#average_reg_accuracy_score = accuracy_score(y_true=y_test, y_pred=average_regression)\n",
    "average_reg_accuracy_score = sm.r2_score(y_true=y_test, y_pred=average_regression)\n",
    "print(\"Regression Score of Averaged Regression:\", round(average_reg_accuracy_score*100, 2),\"%\")\n",
    "#bagged_average_reg_accuracy_score = accuracy_score(y_true=y_test, y_pred=bagged_average_regression)\n",
    "bagged_average_reg_accuracy_score = sm.r2_score(y_true=y_test, y_pred=bagged_average_regression)\n",
    "print(\"Regression Score of Bagged Averaged Regression:\", round(bagged_average_reg_accuracy_score*100, 2),\"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69dcf17a",
   "metadata": {
    "scrolled": false
   },
   "source": [
    "# STEP 5: Post-Ensemble Analysis + Tweaking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "423ddb23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bagged MSE without Linear Regressor:\n",
      "Mean Squared Error of Bagged Decision Tree Regressor: 69566.01340604988\n",
      "Mean Squared Error of Bagged Random Forest Regressor: 65897.9893130154\n",
      "Mean Squared Error of Bagged MLP Regressor: 160252.64662896984\n",
      "\n",
      "\n",
      "Fusion: Bagged Average of Predictions\n",
      "Index\tPrediction\n",
      "0 \t 1383.0\n",
      "1 \t 287.0\n",
      "2 \t 1591.0\n",
      "3 \t 594.0\n",
      "4 \t 938.0\n",
      "\n",
      "Bagged Averaged Regression without Linear Regression:\n",
      "\tMean Squared Error: 79176\n",
      "\tRegression Score: 80.95 %\n"
     ]
    }
   ],
   "source": [
    "# See how the model performs without Linear Regression. Keep Bagging\n",
    "print_switch = True\n",
    "\n",
    "print(\"Bagged MSE without Linear Regressor:\")\n",
    "print(\"Mean Squared Error of Bagged Decision Tree Regressor:\",Bagged_MSE_Decision_Tree_Regressor)\n",
    "print(\"Mean Squared Error of Bagged Random Forest Regressor:\",Bagged_MSE_Random_Forest_Regressor)\n",
    "print(\"Mean Squared Error of Bagged MLP Regressor:\",Bagged_MSE_MLP_Regressor)\n",
    "print(\"\\n\")\n",
    "Total_Number_of_Regressors = 3 # useful for calculating averages\n",
    "\n",
    "# Fusion - Average of Regressions - Bagged\n",
    "bagged_average_regression = np.zeros(y_test.size)\n",
    "for i in range (y_test.size):\n",
    "    tree_r = Bagged_Decision_Tree_Regressor_Predictions[i]\n",
    "    rand_tree_r = Bagged_Random_Forest_Regressor_Predictions[i]\n",
    "    mlp_r = Bagged_MLP_Regressor_Predictions[i]\n",
    "    \n",
    "    sum_reg =  (tree_r + rand_tree_r + mlp_r)\n",
    "    bagged_average_regression[i] = round(sum_reg/Total_Number_of_Regressors)\n",
    "\n",
    "if (print_switch):\n",
    "    print(\"Fusion: Bagged Average of Predictions\")\n",
    "    print(\"Index\\tPrediction\")\n",
    "    for i in range (5):\n",
    "        print(i,\"\\t\",bagged_average_regression[i])\n",
    "\n",
    "print(\"\")\n",
    "print(\"Bagged Averaged Regression without Linear Regression:\")\n",
    "Bagged_MSE_average_reg = mean_squared_error(y_true=y_test, y_pred=bagged_average_regression)\n",
    "print(\"\\tMean Squared Error:\",round(Bagged_MSE_average_reg))\n",
    "bagged_average_reg_accuracy_score = sm.r2_score(y_true=y_test, y_pred=bagged_average_regression)\n",
    "print(\"\\tRegression Score:\", round(bagged_average_reg_accuracy_score*100, 2),\"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd294e4c",
   "metadata": {},
   "source": [
    "# EXTRA: Potential Exploration Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5ca77990",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add SARIMAX testing?\n",
    "# add other extra tests?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aab9198",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
